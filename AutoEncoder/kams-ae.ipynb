{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing dataset\n",
    "movies = pd.read_csv('ml-1m/movies.dat',sep='::',header=None, engine='python', encoding='latin-1')\n",
    "users = pd.read_csv('ml-1m/users.dat',sep='::',header=None, engine='python', encoding='latin-1')\n",
    "ratings = pd.read_csv('ml-1m/ratings.dat',sep='::',header=None, engine='python', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating training and test set\n",
    "training_set = pd.read_csv('ml-100k/u1.base',delimiter='\\t')\n",
    "training_set = np.array(training_set,dtype='int')\n",
    "\n",
    "test_set = pd.read_csv('ml-100k/u1.test',delimiter='\\t')\n",
    "test_set = np.array(test_set,dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of users and movies\n",
    "nb_users = max(max(training_set[:,0]), max(test_set[:,0]))\n",
    "nb_movies = max(max(training_set[:,1]), max(test_set[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting data to array with users in lines and moviews in columns\n",
    "def convert(data):\n",
    "    new_data = []\n",
    "    for id_users in range(1, nb_users+1):\n",
    "        id_movies = data[:,1][data[:,0]==id_users]\n",
    "        id_ratings = data[:,2][data[:,0]==id_users]\n",
    "        ratings = np.zeros(nb_movies)\n",
    "        ratings[id_movies - 1] =id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data\n",
    "\n",
    "training_set = convert(training_set)\n",
    "test_set = convert(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting to torch tensors\n",
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a AE class\n",
    "class SAE(nn.Module):\n",
    "    \n",
    "    def __init__(self, ):\n",
    "        super(SAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(nb_movies, 20) #Getting 20 hidden features\n",
    "        self.fc2 = nn.Linear(20,10) #This is similar to neurons added in DL\n",
    "        self.fc3 = nn.Linear(10,20)\n",
    "        self.fc4 = nn.Linear(20,nb_movies)\n",
    "        self.activation = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x= self.activation(self.fc1(x))\n",
    "        x= self.activation(self.fc2(x))\n",
    "        x= self.activation(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae = SAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(sae.parameters(), lr=0.01, weight_decay = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1loss: tensor(1.7676)\n",
      "epoch: 2loss: tensor(1.0967)\n",
      "epoch: 3loss: tensor(1.0536)\n",
      "epoch: 4loss: tensor(1.0383)\n",
      "epoch: 5loss: tensor(1.0307)\n",
      "epoch: 6loss: tensor(1.0266)\n",
      "epoch: 7loss: tensor(1.0239)\n",
      "epoch: 8loss: tensor(1.0218)\n",
      "epoch: 9loss: tensor(1.0209)\n",
      "epoch: 10loss: tensor(1.0197)\n",
      "epoch: 11loss: tensor(1.0190)\n",
      "epoch: 12loss: tensor(1.0184)\n",
      "epoch: 13loss: tensor(1.0177)\n",
      "epoch: 14loss: tensor(1.0177)\n",
      "epoch: 15loss: tensor(1.0172)\n",
      "epoch: 16loss: tensor(1.0169)\n",
      "epoch: 17loss: tensor(1.0167)\n",
      "epoch: 18loss: tensor(1.0165)\n",
      "epoch: 19loss: tensor(1.0164)\n",
      "epoch: 20loss: tensor(1.0161)\n",
      "epoch: 21loss: tensor(1.0159)\n",
      "epoch: 22loss: tensor(1.0161)\n",
      "epoch: 23loss: tensor(1.0161)\n",
      "epoch: 24loss: tensor(1.0158)\n",
      "epoch: 25loss: tensor(1.0156)\n",
      "epoch: 26loss: tensor(1.0157)\n",
      "epoch: 27loss: tensor(1.0152)\n",
      "epoch: 28loss: tensor(1.0148)\n",
      "epoch: 29loss: tensor(1.0127)\n",
      "epoch: 30loss: tensor(1.0111)\n",
      "epoch: 31loss: tensor(1.0109)\n",
      "epoch: 32loss: tensor(1.0078)\n",
      "epoch: 33loss: tensor(1.0076)\n",
      "epoch: 34loss: tensor(1.0031)\n",
      "epoch: 35loss: tensor(1.0033)\n",
      "epoch: 36loss: tensor(0.9990)\n",
      "epoch: 37loss: tensor(0.9993)\n",
      "epoch: 38loss: tensor(0.9964)\n",
      "epoch: 39loss: tensor(0.9952)\n",
      "epoch: 40loss: tensor(0.9919)\n",
      "epoch: 41loss: tensor(0.9905)\n",
      "epoch: 42loss: tensor(0.9888)\n",
      "epoch: 43loss: tensor(0.9869)\n",
      "epoch: 44loss: tensor(0.9847)\n",
      "epoch: 45loss: tensor(0.9820)\n",
      "epoch: 46loss: tensor(0.9807)\n",
      "epoch: 47loss: tensor(0.9831)\n",
      "epoch: 48loss: tensor(0.9786)\n",
      "epoch: 49loss: tensor(0.9775)\n",
      "epoch: 50loss: tensor(0.9743)\n",
      "epoch: 51loss: tensor(0.9767)\n",
      "epoch: 52loss: tensor(0.9764)\n",
      "epoch: 53loss: tensor(0.9790)\n",
      "epoch: 54loss: tensor(0.9743)\n",
      "epoch: 55loss: tensor(0.9746)\n",
      "epoch: 56loss: tensor(0.9717)\n",
      "epoch: 57loss: tensor(0.9705)\n",
      "epoch: 58loss: tensor(0.9661)\n",
      "epoch: 59loss: tensor(0.9668)\n",
      "epoch: 60loss: tensor(0.9643)\n",
      "epoch: 61loss: tensor(0.9656)\n",
      "epoch: 62loss: tensor(0.9640)\n",
      "epoch: 63loss: tensor(0.9636)\n",
      "epoch: 64loss: tensor(0.9667)\n",
      "epoch: 65loss: tensor(0.9689)\n",
      "epoch: 66loss: tensor(0.9641)\n",
      "epoch: 67loss: tensor(0.9647)\n",
      "epoch: 68loss: tensor(0.9658)\n",
      "epoch: 69loss: tensor(0.9623)\n",
      "epoch: 70loss: tensor(0.9622)\n",
      "epoch: 71loss: tensor(0.9627)\n",
      "epoch: 72loss: tensor(0.9602)\n",
      "epoch: 73loss: tensor(0.9636)\n",
      "epoch: 74loss: tensor(0.9647)\n",
      "epoch: 75loss: tensor(0.9671)\n",
      "epoch: 76loss: tensor(0.9627)\n",
      "epoch: 77loss: tensor(0.9604)\n",
      "epoch: 78loss: tensor(0.9603)\n",
      "epoch: 79loss: tensor(0.9597)\n",
      "epoch: 80loss: tensor(0.9583)\n",
      "epoch: 81loss: tensor(0.9540)\n",
      "epoch: 82loss: tensor(0.9523)\n",
      "epoch: 83loss: tensor(0.9528)\n",
      "epoch: 84loss: tensor(0.9550)\n",
      "epoch: 85loss: tensor(0.9532)\n",
      "epoch: 86loss: tensor(0.9509)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-099683241ee0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m       \u001b[0mmean_corrector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnb_movies\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1e-10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m       \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m       \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmean_corrector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m       \u001b[0ms\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ganesh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ganesh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training SAE\n",
    "nb_epoch = 200\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "  train_loss = 0\n",
    "  s = 0.\n",
    "  for id_user in range(nb_users):\n",
    "    input = Variable(training_set[id_user]).unsqueeze(0)\n",
    "    target = input.clone()\n",
    "    if torch.sum(target.data > 0) > 0:\n",
    "      output = sae(input)\n",
    "      target.require_grad = False\n",
    "      output[target == 0] = 0\n",
    "      loss = criterion(output, target)\n",
    "      mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "      loss.backward()\n",
    "      train_loss += np.sqrt(loss.data*mean_corrector)\n",
    "      s += 1.\n",
    "      optimizer.step()\n",
    "  print('epoch: '+str(epoch)+'loss: '+ str(train_loss/s))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
